{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Bag of words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Define una lista `docs` con todos los archivos contenidos en este directorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['doc1.txt', 'doc2.txt', 'doc3.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define una lista vacia `corpus` que contendrá el contenido de los archivos. Haz un bucle con `docs` y almacena su  contenido en `corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTA IMPORTANTE: En Python, cuando se trabaja con archivos, es importante cerrarlos una vez que se han terminado de usar.\n",
    "# la palabra reservada \"with\" contiene un try/except/finally y garantiza que si se produce alguna excepción el\n",
    "# programa cerrará el archivo antes de salir. Esta es una estructura habitual para manejar archivos.\n",
    "corpus = []\n",
    "\n",
    "for i in docs:\n",
    "    with open(i) as file:\n",
    "        content = file.read()\n",
    "        corpus.append(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Imprime el contenido de los documentos cargados en `corpus` para visualizarlos ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Desde ahora Data es tu aliado.', 'Data solo es una palabra, tu no.', 'Data es el camino.']\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Quita los signos de puntuacion de cada una de las cadenas de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Convierte todos los elementos de cada una de las cadenas de texto a minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Desde ahora Data es tu aliado', 'Data solo es una palabra tu no', 'Data es el camino']\n"
     ]
    }
   ],
   "source": [
    "# usando metodos de string elimina todos los signos de puntuacion de cada documento\n",
    "corpus = [doc.replace('.', '').replace(',','') for doc in corpus]\n",
    "print(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['desde ahora data es tu aliado', 'data solo es una palabra tu no', 'data es el camino']\n"
     ]
    }
   ],
   "source": [
    "# usando metodos de los stirngs convierte todo a minusculas\n",
    "corpus = [doc.lower() for doc in corpus]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['desde ahora data es tu aliado',\n",
       " 'data solo es una palabra tu no',\n",
       " 'data es el camino']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizando regex\n",
    "# El patrón de búsqueda es: cualquier carácter excepto .\n",
    "# El patrón de búsqueda es: [.]\n",
    "\n",
    "import re  \n",
    "\n",
    "for doc, content in enumerate(corpus):  # Para cada documento y contenido\n",
    "    corpus[doc] = re.sub('[.]', '', content).lower()  # Sustituyo el contenido del documento aplicando regex\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora define `bag_of_words` como una lista vacía. Contendrá los cada string único del `corpus`.\n",
    "\n",
    "Itera la lista \"corpus\". En cada iteracion, haz lo siguiente: \n",
    "\n",
    "> Divide la cadena en una matriz de términos. \n",
    "\n",
    "> Crea un \"sub-bucle\" para iterar por la matriz de términos. En cada sub-bucle, comprueba si el término actual ya está contenido en `bag_of_words`. Si no está en `bag_of_words`, añádelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = []\n",
    "\n",
    "for content in corpus:  # Para cada lista de contenido, separo las palabras\n",
    "    content = content.split()\n",
    "\n",
    "    for word in content:  # Para cada palabra, compruebo si la tengo\n",
    "        if word not in bag_of_words:\n",
    "            bag_of_words.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Imprime `bag_of_words`.\n",
    "\n",
    "La salida deberias ver la siguiente salida ['desde','ahora', 'data', 'es', 'tu', 'aliado', 'solo', 'una', 'palabra,', 'no','el', 'camino']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['desde',\n",
       " 'ahora',\n",
       " 'data',\n",
       " 'es',\n",
       " 'tu',\n",
       " 'aliado',\n",
       " 'solo',\n",
       " 'una',\n",
       " 'palabra',\n",
       " 'no',\n",
       " 'el',\n",
       " 'camino']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ahora definimos una lista vacía llamada `term_freq`. Repite el bucle `corpus` por segunda vez. En cada bucle, crea un sub-bucle para iterar los términos en `bag_of_words`. Cuenta cuántas veces aparece cada término en cada documento del `corpus`. Añade la matriz de frecuencia de términos a `term_freq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0],\n",
       " [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq = []\n",
    "term_freq_sublist = []  # Genero una sublista para cada doc de corpus\n",
    "\n",
    "for content in corpus:  # Recorro corpus de nuevo\n",
    "    content = content.split()\n",
    "\n",
    "    for word in bag_of_words:  # Recorro la lista de palabras\n",
    "        term_freq_sublist.append(content.count(word))  # Cuento y añado a la sublista\n",
    "\n",
    "    term_freq.append(term_freq_sublist)  # Añado la sublista\n",
    "    term_freq_sublist = []  # Vacío la sublista para empezar de nuevo\n",
    "\n",
    "term_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Imprime `bag_of_words`.\n",
    "\n",
    "La salida tiene que ser la siguiente \n",
    "\n",
    "`[[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
    " [0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0],\n",
    " [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1]]`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
